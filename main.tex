\documentclass{article}
\usepackage{proof}
\usepackage{bussproofs}
\usepackage{xcolor}
\usepackage{url}
\usepackage{framed}
\usepackage{amsmath, amsfonts, amssymb}
\usepackage{mathtools}

\begin{document}
\title{SMT Solvers and Proof Assistants}
\author{Arjun Viswanathan}
\date{}
\maketitle
\begin{abstract}
	Interactive theorem provers (ITPs) and automatic theorem provers (ATPs)
	are two distinct categories of theorem provers on different ends 
	of the spectrum of verifiers. On one hand, 
	ITPs are typically robust tools with a small, verified kernel 
	allowing for a high degree of reliability. However, they 
	require user intervention in the proving process, only
	offering a minimal amount of automation. ATPs, on the other hand, 
	are push-button theorem provers that use complex heuristics to prove 
	theorems; as a consequence, they have a large code-base that is hard 
	to maintain and susceptible to bugs. A lot of recent research 
	has focused on bridging the gap between these two poles 
	of theorem proving. For instance, hammers and certified checkers 
	are tools that were born from this research, that have different 
	approaches to this problem. This work aims to 
	comprehensively study these different tools 
	from the point of view of using SMT solvers as
	the ATPs enhancing automation in ITPs.
\end{abstract}

\section{Introduction}
\label{sec:intro}
	Interactive theorem provers (ITPs) or proof assistants are 
	software tools that allow formalizing of mathematical proofs.
	They provide an expressive logic to state theorems in, and 
	an interactive interface through which the user can 
	attempt to prove these theorems using methods 
	called tactics. Generally, this interface mimics a 
	written mathematical proof with a context and a goal 
	that changes on the fly as one steps through the parts 
	of the proof. The data structures provided by the ITP are 
	minimal and the user's mathematical structures are 
	defined on top of these, keeping the verified kernel of the 
	ITP small. These proofs provide a high level of reliability
	but are hard to come up with from the user's point of view. 
	
	Automatic theorem provers (ATPs) have grown rapidly over the 
	past decades and refer to tools that allow automatic proving 
	of logical formulas. Interaction between the user and the 
	ATP is kept to a minimum; ideally, the user would provide a 
	theorem to the ATP and the ATP either proves it or comes up
	with a counter-example that disproves it. For this work, we 
	will look at a particular sub-category of ATPs called 
	satisfiability modulo theories (SMT)-solvers. SMT solvers 
	input formulas in first order logic with equality and 
	other background theories such as (integer, real, and 
	machine integer) arithmetic, arrays, etc. and determine
	whether the formula is satisfiable or not. Depending 
	on the theory, and whether quantification
	is enabled, the SMT-solver could also fail to answer the query. 
	This satisfiability problem is the dual of the 
	validity problem (proving a formula to be valid) - a 
	formula can be proved to be valid by establishing that 
	its negation is unsatisfiable. We focus only on 
	quantifier-free fragments of the logic, which is in keeping 
	with the present state-of-the-art. Although ATPs can also 
	refer to superposition provers such as Vampire and SPASS, 
	which have also been successfully used to provide 
	automation to ITPs, the focus here is on leveraging 
	SMT-solvers in ITPs.
	
	ATPs and ITPs clearly have different modes of operations
	and offer distinct advantages - ITPs certify their 
	results with a high degree of trustworthiness although 
	reaching the proofs might take some time and effort from 
	the user; ATPs offer relatively quick and automated results, 
	while not giving the same kind of guarantees that ITPs do.
	A natural research question is whether we can get the best 
	of both worlds - reliable proofs with maximum automation. 
	\textcolor{red}{Generalize?}
	In this work, we compare Sledgehammer and SMTCoq, 
	two tools that take different approaches 
	to this goal. A hammer helps an ITP prove lemmas by using 
	an ATP to guide its proof search, and Sledgehammer is
	the very first of these. On the other hand, 
	a certified checker is more tightly integrated with the ATP 
	- it also converts proofs produced by the ATPs and 
	checks them within the ITP. Thus, it gets results 
	from outside the ITP but certifies them by checking them
	inside the ITP. SMTCoq is a certified checker 
	for the Coq proof assistant that uses SAT and SMT solvers
	for automation.
	
	\textcolor{red}{Insert an image of a graph with SMT solvers
	on one axis and proof assistants on the other, with
	Sledgehammer and SMTCoq in the middle}

	\textcolor{red}{Give a preview of the rest of the paper here}

\section{Formal Preliminaries}
\label{sec:prelim}

\section{Related Work}
\label{sec:rel}
	\textcolor{red}{QED Manisfesto}\\
	\textcolor{red}{Hammer for resolution provers?}\\
	\textcolor{red}{CoqHammer}\\
	\textcolor{red}{Check related work of both papers.}\\
	\textcolor{red}{NQTHM and ACL2 are the earliest combination of ATPs and ITPs according to the SMTCoq paper}
	In ~\cite{10.1007/978-3-642-14052-5_14}, they integrate 
	Z3 with Isabelle/HOL and HOL4 
	using proof replaying, that is to verify 
	the Z3 proofs in the ITP, similar to SMTCoq. However, 
	~\cite{10.1007/978-3-642-22438-6_11} mentions that this
	integration wasn't useful. Instead, the reconstruction 
	method using the in-house Metis solver was more 
	successful. 
	
\section{Automatic Theorem Provers}
\label{sec:atp}	
\subsection{SMT-Solvers}
\label{smt}
	Boolean satisfiability, often called the SAT problem, 
	is the problem of satisfying a Boolean formula, that is, 
	consistently assigning values of $True$ or $False$ 
	to the variables of the formula so that the entire 
	formula evaluates to $True$. For example,
	\begin{center}$(x \lor y) \land z$ \end{center}
	can be satisfied by the 
	assignment $\{x=True,\ y=False,\ z=True\}$. On the other hand, 
	\begin{center} $x \land \neg x$ \end{center}
	is unsatisfiable, no matter what value is assigned to $x$.
	
	Satisfiability Modulo Theories~\cite{DBLP:reference/mc/BarrettT18} 
	or SMT lifts SAT to a level that includes theories. 
	For example, 
	\begin{center} $(a = b) \land (b = c) \land \neg (a = c)$ 
	\end{center}
	is a formula that is unsatisfiable in the theory of 
	equality over uninterpreted functions. This is because, by
	transitivity of $a = b$ and $b = c$, we have $a = c$. SMT 
	allows us to be more expressive with our formulas, but 
	this comes at the cost of more complicated decision 
	procedures.
	
	SMT solvers have plenty of applications in formal methods 
	and software verification. For instance, SMT solvers are used 
	in the back-end of model checkers~\cite{DBLP:books/daglib/0020348}, 
	which input mathematical 
	models of a software system, and verify whether they 
	satisfy a particular property or not. Another area of 
	application is symbolic
	execution~\cite{DBLP:journals/csur/BaldoniCDDF18}, 
	which is to analyze a 
	program to figure out what set of inputs work for each 
	part of the program. Other uses of SMT solvers include 
	program synthesis~\cite{synth}, static analysis, 
	and interpolant generation~\cite{DBLP:journals/corr/abs-1111-5652}.
	
	Due to the recent emphasis on verifying results from SMT-solvers,
	\textcolor{red}{Find a citation}
	many SMT-solvers are proof producing. When an SMT-solver finds 
	that a formula is satisfiable, an easily checkable proof of this is 
	a satisfying model of the formula. However, when a solver 
	concludes that a formula is unsatisfiable, it is more difficult 
	to produce an acceptable proof of this. Most SMT-solvers 
	follow some version of the DPLL(T) algorithm, which tries
	to satisfy the formula by propagating assignments, making 
	choices on assignments when necessary, and concluding unsat
	when all choices have been tried. Since this algorithm 
	primarily operates on the resolution principle, 
	a universally accepted proof calculus is one based 
	on resolution. Specifically, a proof of unsatisfiability 
	of a formula in CNF, is a tree with the input 
	clauses and theory lemmas at the leaves, and the empty 
	clause at the root. The resolution takes two clauses, 
	a pivot element that occurs with opposite polarities 
	in each of the clauses, and gives one clause that is 
	a consequent of the premises. The idea is that, beginning 
	with the input clauses and the theory lemmas (which might 
	have their own sub-proof trees coming from the theory solvers), 
	the tree derives that the empty clause holds, which is the 
	most basic notion of unsatisfiability since the there 
	is no way to satisfy the empty clause.
	
	\begin{center}
		$\infer[resolution]{\phi_1 \lor ... \lor \phi_n \lor 
			\psi_1 \lor ... \lor \psi_m}
		{\phi_1 \lor ... \lor \phi_n \lor \chi & \neg \chi 
			\lor \psi_1 \lor ... \lor \psi_m}$ 
	\end{center}
	For instance,
	\begin{center}
		$\infer{a \lor c}{a \lor \neg b & b \lor c}$
	\end{center}
	\textcolor{red}{Insert a figure of the proof}
	
	Even though the calculus is common among the SMT-solvers, 
	it hasn't been standardized. CVC4 uses a proof language called
	LFSC or (Logical Framework with Side Conditions) that mixes 
	declarative rules with computable programs; veriT uses a rule-bases 
	calculus defined in a SMTLIB like syntax; Z3 uses a rule based 
	calculus with a relatively lower level of granularity. 
	
	\subsection{Superposition Provers}
	\label{sup}
	Superposition provers or resolution provers differ 
	from SMT solvers in that they focus on proving 
	conjectures rather than finding a satisfiable model
	for a set of formulas. The problem is formulated 
	as a set of axioms that relate to the problem space, 
	a set assumptions and a conjecture to prove. 
	The goal is to find the unsatisfiability of 
	the negation of the conjecture along with the 
	assumptions and the axioms, and this is done 
	by refutation. The prover converts 
	the input formulas into a set of clauses and 
	uses a small set of inference rules to add 
	implied clauses to the input set of 
	clauses - ultimately it tries to derive 
	the empty clause or figure out that this 
	isn't possible. These provers are resolution-based -
	the most important rule in the calculus is the 
	\textit{resolution} rule. This has evolved into 
	the \textit{paramodulation} rule to accommodate 
	the notion of equality, and ultimately into 
	the \textit{superposition} rules that take into 
	consideration, along with equality, an ordering 
	on the terms in the clauses to reduce the number 
	of rule applications.
	
	At the leaves are axioms or assumptions, and 
	each node is obtained using one or more inference
	rules applied on previous nodes/leaves. 
	A proof trace is a DAG with the empty clause at
	the root. The inference rules are sound and 
	usually theoretically complete, but in practice 
	this might be only true with infinite resources.
	
	Popular resolution provers like Vampire, E, and 
	SPASS adhere to the TPTP (Thousands of Problems 
	for Theorem Provers) input/output standard.
	
	The superposition prover applies the inference 
	rules to the input set of 
	clauses until saturation - that is until the 
	resultant set of clauses is closed under the 
	inference rules. To keep this system
	efficient, provers use an ordering 
	on the terms. The saturation algorithm used 
	by the prover guides the process of adding the 
	next inference rule based on this simplification 
	ordering of terms.
	
	Given $S$, the set of input clauses, the possible 
	outcomes of a superposition prover are:
	\begin{enumerate}
		\item The empty clause is derived from $S$, and
		$S$ is unsatisfiable.
		\item The solver terminates without generating the 
		empty clause, and $S$ is satisfiable.
		\item The saturation algorithm doesn't terminate 
		before the prover runs out of resources, and 
		the empty clause isn't generated. In this 
		case, the result is unknown. 
	\end{enumerate}
	
	Since there may be redundance in the application 
	of inference rules, and the generated clauses, 
	many provers work on minimizing this redundance in 
	interest of efficiency.
	
	Resolution provers deal with theories by 
	adding an axiomatisation of the theory to the 
	leaves of the DAG before running the 
	saturation algorithm.
	
	While both SMT solvers and superposition provers 
	produce resolution proofs, SMT solvers are guided 
	by trying to find a satisfying model to an input 
	problem whereas superposition provers try 
	to prove the negation of conjecture to be unsatisfiable
	with the remaining assertions in the problem. 
	
	Additionally, theories are built-in for SMT solvers,
	while they need to be externally axiomatized for 
	resolution provers. As such, superposition provers
	are better suited for quantified formulas and 
	minimal theory reasoning, whereas SMT solvers 
	do well on problems that contain constraints 
	in theories and quantified formulas slow them 
	down.
	
\section{Proof Assistants}
\label{itp}
	
\section{Hammers}
\label{gen-hammers}
	Hammers use ATPs to automate the proving of goals within ITPs
	that depend on certain other lemmas. A hammer is composed of 
	a premise selector, which is a method to identify relevant 
	premises that help prove a goal; a translator that bridges 
	the gap between the logic of the ATP and that of the ITP; 
	and a proof reconstructor that processes the ATPs proof
	within the ITP.
	
	\subsection{Premise Selection}
		While queries to SMT solvers are contained within a single 
		file, this isn't necessarily the case for ITPs. An SMT file
		typically consists along with declarations and definitions 
		of a set of assertions and a query that checks whether 
		their conjunction is satisfiable or not. 
		One can imagine a set of hypotheses 
		$H_1, H_2, ..., H_n$ and a conjecture $G$, with a 
		typical goal in an ITP that looks like $L$:
		\begin{center}
			$L : H_1 \to H_2 \to ... \to H_n \to G$.
		\end{center}
		Proving $L$ is equivalent to proving the unsatisfiability 
		of $\neg L$.
		\begin{align*}
			\neg L &= \neg (H_1 \to H_2 \to ... \to H_n \to G)\\
			&= \neg (\neg H_1 \lor \neg H_2 \lor ... \lor \neg H_n \lor G)
			& \text{by unfolding }\to \\
			&= \neg \neg H_1 \land \neg \neg H_2 \land ... \land \neg \neg H_n 
			\land \neg G
			& \text{by De Morgan's law}\\
			&= H_1 \land H_2 \land ... \land H_n \land \neg G
			& \text{by double negation elimination}
		\end{align*}
	
		So the problem can equivalently be stated in the context of ATPs
		as checking the unsatisfiability of a set of hypotheses 
		along with the negation of the conjecture. This would look 
		like the following SMT file:
		\begin{verbatim}
			assert H_1
			assert H_2
			...
			assert H_n
			assert (not G)
			check-sat
		\end{verbatim}
		However, goals in ITPs aren't necessarily self-contained 
		as in $L$. The hypotheses needed to prove $G$ 
		might have been proven earlier. In fact, ITPs have large
		libraries of proven lemmas any of which might be potentially 
		useful in proving a goal $G$. As such, picking
		the hypotheses to send along with the negation of the 
		goal to an ATP is challenging. This is called premise 
		selection. The most basic form of premise selection 
		is to allow for the user to find relevant facts 
		to prove a conjecture. But given that these libraries 
		have hundreds of lemmas, automatic methods to select 
		premises is a more scalable and generalizable approach.
	
		Historically, premise selection was delegated to the 
		user, but modern hammers have plenty of ways to 
		automate this process. Some that use machine learning
		to learn axiom selection from previously successful 
		proofs using methods such as ones based on 
		Bayesian statistics \cite{DBLP:journals/jar/AlamaHKTU14}, 
		a nearest-neighbor ranking function 
		\cite{DBLP:conf/cade/KaliszykU13a}, and non-linear 
		kernel methods \cite{DBLP:journals/jar/AlamaHKTU14}.
		Others use simpler algorithms; the relevance filter 
		by Meng and Paulson 
		\cite{DBLP:journals/japll/MengP09}
		for the Isabelle/HOL ITP selects relevant facts by 
		giving priority to the number of symbols in common 
		with the goal. The SInE (SUMO Inference Engine) 
		\cite{10.1007/978-3-642-22438-6_23} does something 
		similar in the ATP Vampire. The Divvy system 
		\cite{10.1007/978-3-642-02959-2_13} also uses a 
		syntactic relevance filtering technique but it 
		selects from the ordered facts from the middle, 
		instead of doing it from the top of the list; it
		also uses an ordering technique based 
		on latent semantics called APRILS (Automated 
		Prophesier of Relevance Incorporating Latent Semantics).
		Others use semantics instead of syntax to guide
		the selection process. For instance, the SRASS 
		(Semantic Relevance Axiom Selection System) 
		\cite{10.1007/978-3-540-73595-3_20} finds 
		countermodels of the conjecture and selects axioms that
		exclude the countermodels. Other research combined
		these various types of methods to increase efficiency 
		\cite{DBLP:journals/corr/KaliszykU13b, 
			10.1007/978-3-642-31365-3_30}.
		
		\subsection{Translation}
		ITPs allow for a more expressive higher-order logic 
		with set-theoretic notation, whereas ATPs are mostly 
		restricted to first-order logic. Thus, not all 
		ITP problems are transferable to an ATP. However, 
		there is a large enough subset of problems provable
		by an ATP that can help an ITP user. When a goal is 
		provable by an ATP, it needs to be soundly translated 
		to its logic. The translation can involve various 
		tricks to eliminate higher-order constructs
		\cite{DBLP:journals/jar/MengP08} 
		such as higher order quantification, partial 
		function applications, and anonymous functions
		from the goal, and an encoding of any 
		type information where necessary. Resolution 
		provers usually don't have 
		in-built types, so a theory must be externally 
		axiomatized within the ATP. With SMT solvers, there
		maybe a stronger correspondence between some types and 
		sorts. 
	
		\subsection{Proof Reconstruction}
		Once the goal is translated to a problem understandable 
		to the ATP, the result from the ATP needs to be 
		soundly translated back to a valid ITP output.
		As previously mentioned, the validity of a goal in 
		the ITP corresponds to the unsatisfiability of its 
		negation in the ATP. If it is satisfiable, this 
		translates to a counterexample of the fact that 
		the goal holds. Hammers sometimes use ATPs 
		in this way to avoid wasting time proving 
		unprovable goals. More interestingly, if the 
		goal is found to be unsatisfiable in the ATP, 
		the refutation proof of its unsatisfiability
		needs to be consumed by the ITP. In its simplest form,
		this pipeline consists of using the ATP as an oracle, 
		that is to consider the goal to be proven in the 
		ITP if the ATP concludes that its negation is 
		unsatisfiable. This compromises the ITP's 
		trustworthiness and adds to the the trust-base, 
		the entire ATP.
		
		One way of doing this is to independently reconstruct 
		the proof in the proof assistant once the ATP finds 
		the goal to be unsatisfiable. In this case, the 
		only information the ITP gets from the ATP is that 
		the goal is provable given the premises. It does 
		not care about how the ATP proved this conjecture.
		Essentially, the ATP acts as a relevance filter for 
		the prover inside the ITP. This is done, for instance, 
		with Isabelle and the Metis prover 
		\cite{10.1007/978-3-540-74591-4_18}. A more involved
		integration involves using in addition to the premises
		the proof steps used by the ATP, as in PRocH
		\cite{10.1007/978-3-642-38574-2_18} that reconstructs 
		TPTP proofs in HOL Light.
		
\section{Sledgehammer}
\label{sec:hammer}
	Isabelle is a proof assistant that allows for the formalizing of mathematical 
	formulas. Isabelle/HOL is an instance of Isabelle that 
	provides an expressive higher-order logic to prove theorems 
	in its proof language Isar, and also consists of a large 
	library of formally verified mathematics. 
	
	Sledgehammer is a component of Isabelle/HOL that uses 
	external ATPs to guide Isabelle/HOL's proving. The ATPs 
	used by Sledgehammer can be classified as resolution 
	provers and SMT-solvers. This section expands on the work 
	done to integrate SMT-solvers with Isabelle/HOL via 
	Sledgehammer.
	
	When a user wishes to find a proof for a conjecture using 
	Sledgehammer, it first picks a few hundred relevant 
	lemmas from Isabelle's libraries and sends them along 
	with the conjecture to the ATP. The conjecture is 
	translated from Isabelle's polymorphic higher-order 
	logic to the ATP's first order logic. Sledgehammer 
	runs this query parallelly by invoking all available 
	ATPs. If the ATP is able to prove the conjecture, 
	Isabelle's own prover metis sets out to reconstruct 
	this proof. So essentially, the ATP just tells Isabelle 
	when it doesn't need to bother proving a conjecture at 
	all. \textcolor{red}{I'm thinking of a use case here: 
	when I try to use the ITP and I have a subgoal, and I 
	call Sledgehammer and it tells me its not provable, 
	thanks to the ATP, do I just quit? Check out the usage.}
	Additionally, metis also minimizes the proof because 
	the ATPs could have needed many more lemmas than necessary.
	
	Sledgehammer has two different methods of integration 
	with SMT-solvers. The first is through an smt proof 
	method in Isabelle that relies on three SMT solvers - 
	it trusts CVC3 and Yices as oracles while performing 
	a step-by-step proof reconstruction of Z3 proofs. 
	\textcolor{red}{Say more about the Z3 stuff here.}
	Sledgehammer sends the conjecture to prove along 
	with any user supplied facts to the SMT solvers 
	using a translation similar to those of the ATPs 
	and then either reconstructs or trusts the SMT solvers
	results. Trusting SMT solvers isn't a dependable 
	technique for previously mentioned reasons. The integration
	with Z3, though successful, wasn't highly used. 
	\textcolor{red}{Mention the results here} The developers
	improved upon this by loosening the integration of 
	Sledgehammer with SMT solvers in their next attempt.
	
	Sledgehammer reuses the architecture for the ATPs 
	in its second attempt at leveraging SMT solvers. 
	After relevance filtering of facts and translation to 
	first order logic, if the SMT solver is able to
	prove a conjecture, Sledgehammer tries to completely
	reconstruct the proof locally using metis. If metis fails,
	it then tries to reconstruct the proof step-by-step using 
	the smt method. metis cannot handle theories other 
	than equality so it does have to rely on the smt proof
	method for those.
	
\section{SMTCoq}
\label{sec:cert}
	SMTCoq is a Coq plugin that uses SAT and SMT solvers to 
	prove goals in Coq. Another way of looking at it is 
	to think of SMTCoq as a checker for results produced 
	by the SMT solver. SMTCoq allows the user to query 
	a number of SAT/SMT solvers and if the solver is able 
	to validate the query, that is, it determines that 
	the negation of the conjecture is unsatisfiable, it 
	produces a proof of unsatisfiability, which is checked 
	in Coq.
	
	Since different SMT solvers produce resolution 
	proofs of unsatisfiability in different formats, 
	SMTCoq has its own input certificate format. 
	The proofs from the different SMT solvers are 
	translated to an SMTCoq certificate which 
	can then be checked within Coq. Given an input 
	query, the SMT solver first converts into CNF
	(conjunction normal form) which is better 
	suited for resolution proofs. The proof is a 
	resolution proof which might consist of smaller proofs 
	of theory lemmas from the theory solver. 
	SMTCoq takes a modular approach of checking this proof.
	The checker is divided into a main checker that 
	delegates parts of the proof to small checkers. The proof 
	is divided into steps that small checkers can check.
	There is a small checker each for CNF conversion, 
	resolution, and for each theory. The main checker divides the 
	proof into steps, gives the step to the relevant small 
	checker, and checks that in the end, the empty 
	clause is deduced from the initial query. Each small 
	checker operates independently and maintains an invariant
	that allows the checking process to be split this way.
	
	Currently SMTCoq supports the SAT solvers zChaff and Glucose, 
	and the SMT solvers CVC4 and veriT. 
	
	SMTCoq uses Coq's native arrays to store the clauses, 
	a set of which represent the goal. The main checker 
	handles this initial array of clauses representing the 
	goal in CNF, and each small checker computes a 
	clause that is implied from a subset of the clauses.
	For efficiency, SMTCoq replaces the unnecessary 
	clauses with new ones when it knows that they 
	wont be useful anymore. After all the steps 
	are handled by the small checkers, the main 
	checker checks that the final implied clause is 
	the empty clause.
	
	\textcolor{red}{Deep vs shallow embedding}\\
	\textcolor{red}{Reification}\\
	\textcolor{red}{Important lemmas - the one that equates the embeddings}\\
	
\section{Comparison}
\label{sec:comp}
	The most important difference between SMTCoq and Sledgehammer
	is the extent to which they exploit the external SMT solver. 
	Sledgehammer uses an external SMT-solver to guide it through 
	proof search - it asks the SMT-solver whether a particular 
	conjecture is provable; if the solver says yes, 
	it tries to prove this conjecture in-house, and if it says 
	no, it doesn't attempt to prove it. The SMT-solver thus 
	saves time by telling the ITP which lemmas it shouldn't
	waste its time on. SMTCoq has a more solid connection to 
	the SMT-solver - once the SMT-solver says that a conjecture is 
	provable, it produces a proof of the validity of this 
	conjecture, and SMTCoq, after checking this proof in 
	Coq, certifies the lemma as proved. Thus,
	much more effort goes into making SMTCoq work - not only 
	does the Coq conjecture need to be properly translated to 
	SMTLIB, the proof produced by the SMT-solver also 
	needs to be converted to something understandable 
	by Coq and then checked within Coq. Translating from the ITP's 
	higher order logic to the SMT-solver's first order logic 
	is itself a challenging task that until recently, Sledgehammer 
	had an unsound solution for and SMTCoq still does. 
	\textcolor{red}{Make sure SMTCoq is unsound.} 
	This is ameliorated by the fact that
	SMT-solvers have a common input format in SMTLIB, so the 
	translation has a single target. Matters are more complicate 
	when it comes to proofs produced by SMT-solvers - there isn't 
	a common format of outputs. SMTCoq therefore has to deal with 
	the additional challenge of checking proofs in different 
	formats in Coq. It handles this by adapting the proof 
	format of the veriT SMT-solver and translating proofs 
	from other solvers to this format. While this is an impressive
	effort, it does expand the trust-base to include the 
	translator itself.
	
	\textcolor{red}{Say something about the logic translation \\
		Coq to SMTLIB vs \\
		Isabelle/HOL to SMTLIB.}
	
	\textcolor{red}{premise selection?}
	
	\textcolor{red}{What theories does each tool support?}
	
	\textcolor{red}{evaluation?}
	
	
\section{To-Do}
	\begin{enumerate}
		\item Learn about HOL in SMT-solvers. Why are the approaches 
		so different between the two sets of tools? Obviously because
		HOL vs FOL but why can't this change? FOL tools use unsatisfiability 
		as a dual of validity to prove stuff. HOL tools just use 
		things like induction. And they are able to do this because
		of human intervention?
		\item Compare SMT solvers and ITPs just for propositional 
		logic using a fairly simple example. Perhaps for just propositional 
		logic, we can completely use an ATP within an ITP because 
		of decidability? Then use theories, perhaps LIA, design a simple
		example, show how the SMT solver would solve it, show how the 
		ITP would solve it and then show what happens with 
		Sledgehammer and Coqhammer.
		\item What is the difference between resolution ATPs and SMT 
		solvers and why are ATPs better with problems with quantifiers?
		\item Sledgehammer uses unsat cores, read up on them.
	\end{enumerate}
	
	
\section{Conclusion and Moving Forward}
\label{sec:conc}

\bibliographystyle{abbrv}
\bibliography{bib}

\end{document}